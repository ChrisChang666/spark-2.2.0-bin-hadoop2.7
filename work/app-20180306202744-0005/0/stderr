Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
18/03/06 20:27:46 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 22667@onehaohdd
18/03/06 20:27:46 INFO SignalUtils: Registered signal handler for TERM
18/03/06 20:27:46 INFO SignalUtils: Registered signal handler for HUP
18/03/06 20:27:46 INFO SignalUtils: Registered signal handler for INT
18/03/06 20:27:47 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
18/03/06 20:27:48 WARN Utils: Your hostname, onehaohdd resolves to a loopback address: 127.0.1.1; using 192.168.0.112 instead (on interface wlan0)
18/03/06 20:27:48 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
18/03/06 20:27:48 INFO SecurityManager: Changing view acls to: onehao
18/03/06 20:27:48 INFO SecurityManager: Changing modify acls to: onehao
18/03/06 20:27:48 INFO SecurityManager: Changing view acls groups to: 
18/03/06 20:27:48 INFO SecurityManager: Changing modify acls groups to: 
18/03/06 20:27:48 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(onehao); groups with view permissions: Set(); users  with modify permissions: Set(onehao); groups with modify permissions: Set()
18/03/06 20:27:49 INFO TransportClientFactory: Successfully created connection to /192.168.0.112:58131 after 213 ms (0 ms spent in bootstraps)
18/03/06 20:27:49 INFO SecurityManager: Changing view acls to: onehao
18/03/06 20:27:49 INFO SecurityManager: Changing modify acls to: onehao
18/03/06 20:27:49 INFO SecurityManager: Changing view acls groups to: 
18/03/06 20:27:49 INFO SecurityManager: Changing modify acls groups to: 
18/03/06 20:27:49 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(onehao); groups with view permissions: Set(); users  with modify permissions: Set(onehao); groups with modify permissions: Set()
18/03/06 20:27:49 INFO TransportClientFactory: Successfully created connection to /192.168.0.112:58131 after 3 ms (0 ms spent in bootstraps)
18/03/06 20:27:50 INFO DiskBlockManager: Created local directory at /tmp/spark-03a3315f-7b10-415b-b73d-05272bc2f85f/executor-1f661b00-1eee-4072-b379-2d83b4d06965/blockmgr-97a9e8c6-9fc3-4734-99a9-48baef8fdddd
18/03/06 20:27:50 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
18/03/06 20:27:50 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@192.168.0.112:58131
18/03/06 20:27:50 INFO WorkerWatcher: Connecting to worker spark://Worker@192.168.0.112:60291
18/03/06 20:27:50 INFO TransportClientFactory: Successfully created connection to /192.168.0.112:60291 after 19 ms (0 ms spent in bootstraps)
18/03/06 20:27:50 INFO WorkerWatcher: Successfully connected to spark://Worker@192.168.0.112:60291
18/03/06 20:27:50 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
18/03/06 20:27:50 INFO Executor: Starting executor ID 0 on host 192.168.0.112
18/03/06 20:27:50 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44732.
18/03/06 20:27:50 INFO NettyBlockTransferService: Server created on 192.168.0.112:44732
18/03/06 20:27:50 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
18/03/06 20:27:50 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(0, 192.168.0.112, 44732, None)
18/03/06 20:27:50 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(0, 192.168.0.112, 44732, None)
18/03/06 20:27:50 INFO BlockManager: Initialized BlockManager: BlockManagerId(0, 192.168.0.112, 44732, None)
18/03/06 20:27:50 INFO CoarseGrainedExecutorBackend: Got assigned task 0
18/03/06 20:27:50 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
18/03/06 20:27:51 INFO Executor: Fetching spark://192.168.0.112:58131/jars/data-algorithms-1.0.0.jar with timestamp 1520339263721
18/03/06 20:27:51 INFO TransportClientFactory: Successfully created connection to /192.168.0.112:58131 after 4 ms (0 ms spent in bootstraps)
18/03/06 20:27:51 INFO Utils: Fetching spark://192.168.0.112:58131/jars/data-algorithms-1.0.0.jar to /tmp/spark-03a3315f-7b10-415b-b73d-05272bc2f85f/executor-1f661b00-1eee-4072-b379-2d83b4d06965/spark-696ec5fd-a844-42ad-b7c2-8adb938bad25/fetchFileTemp2299200318102920579.tmp
18/03/06 20:27:51 INFO Utils: Copying /tmp/spark-03a3315f-7b10-415b-b73d-05272bc2f85f/executor-1f661b00-1eee-4072-b379-2d83b4d06965/spark-696ec5fd-a844-42ad-b7c2-8adb938bad25/2330924261520339263721_cache to /home/onehao/soft/spark-2.2.0-bin-hadoop2.7/work/app-20180306202744-0005/0/./data-algorithms-1.0.0.jar
18/03/06 20:27:51 INFO Executor: Adding file:/home/onehao/soft/spark-2.2.0-bin-hadoop2.7/work/app-20180306202744-0005/0/./data-algorithms-1.0.0.jar to class loader
18/03/06 20:27:51 INFO TorrentBroadcast: Started reading broadcast variable 1
18/03/06 20:27:51 INFO TransportClientFactory: Successfully created connection to /192.168.0.112:44875 after 3 ms (0 ms spent in bootstraps)
18/03/06 20:27:51 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.1 KB, free 366.3 MB)
18/03/06 20:27:51 INFO TorrentBroadcast: Reading broadcast variable 1 took 467 ms
18/03/06 20:27:52 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 3.6 KB, free 366.3 MB)
18/03/06 20:27:52 INFO HadoopRDD: Input split: hdfs://localhost:9000/user/onehao/workspace/data-algorithms-book/time_series.txt:0+88
18/03/06 20:27:52 INFO TorrentBroadcast: Started reading broadcast variable 0
18/03/06 20:27:52 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 22.9 KB, free 366.3 MB)
18/03/06 20:27:52 INFO TorrentBroadcast: Reading broadcast variable 0 took 32 ms
18/03/06 20:27:52 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 320.9 KB, free 366.0 MB)
18/03/06 20:27:54 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 2335 bytes result sent to driver
18/03/06 20:27:55 INFO CoarseGrainedExecutorBackend: Got assigned task 1
18/03/06 20:27:55 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
18/03/06 20:27:55 INFO TorrentBroadcast: Started reading broadcast variable 2
18/03/06 20:27:55 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.0 KB, free 366.0 MB)
18/03/06 20:27:55 INFO TorrentBroadcast: Reading broadcast variable 2 took 36 ms
18/03/06 20:27:55 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.4 KB, free 366.0 MB)
18/03/06 20:27:55 INFO HadoopRDD: Input split: hdfs://localhost:9000/user/onehao/workspace/data-algorithms-book/time_series.txt:0+88
18/03/06 20:27:55 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1810 bytes result sent to driver
18/03/06 20:27:55 INFO CoarseGrainedExecutorBackend: Got assigned task 2
18/03/06 20:27:55 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
18/03/06 20:27:55 INFO MapOutputTrackerWorker: Updating epoch to 1 and clearing cache
18/03/06 20:27:55 INFO TorrentBroadcast: Started reading broadcast variable 3
18/03/06 20:27:55 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.4 KB, free 365.9 MB)
18/03/06 20:27:55 INFO TorrentBroadcast: Reading broadcast variable 3 took 37 ms
18/03/06 20:27:55 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.5 KB, free 365.9 MB)
18/03/06 20:27:55 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them
18/03/06 20:27:55 INFO MapOutputTrackerWorker: Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@192.168.0.112:58131)
18/03/06 20:27:55 INFO MapOutputTrackerWorker: Got the output locations
18/03/06 20:27:55 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/03/06 20:27:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 12 ms
18/03/06 20:27:55 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 5039 bytes result sent to driver
18/03/06 20:27:56 INFO CoarseGrainedExecutorBackend: Got assigned task 3
18/03/06 20:27:56 INFO Executor: Running task 0.0 in stage 4.0 (TID 3)
18/03/06 20:27:56 INFO TorrentBroadcast: Started reading broadcast variable 4
18/03/06 20:27:56 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.5 KB, free 365.9 MB)
18/03/06 20:27:56 INFO TorrentBroadcast: Reading broadcast variable 4 took 41 ms
18/03/06 20:27:56 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.8 KB, free 365.9 MB)
18/03/06 20:27:56 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/03/06 20:27:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/03/06 20:27:56 INFO Executor: Finished task 0.0 in stage 4.0 (TID 3). 2492 bytes result sent to driver
18/03/06 20:27:56 INFO CoarseGrainedExecutorBackend: Got assigned task 4
18/03/06 20:27:56 INFO Executor: Running task 0.0 in stage 6.0 (TID 4)
18/03/06 20:27:56 INFO TorrentBroadcast: Started reading broadcast variable 5
18/03/06 20:27:56 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 27.3 KB, free 365.9 MB)
18/03/06 20:27:56 INFO TorrentBroadcast: Reading broadcast variable 5 took 29 ms
18/03/06 20:27:56 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 75.4 KB, free 365.8 MB)
18/03/06 20:27:56 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/03/06 20:27:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/03/06 20:27:56 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
18/03/06 20:27:56 INFO FileOutputCommitter: Saved output of task 'attempt_20180306202756_0006_m_000000_4' to hdfs://localhost:9000/user/onehao/hdoutput/_temporary/0/task_20180306202756_0006_m_000000
18/03/06 20:27:56 INFO SparkHadoopMapRedUtil: attempt_20180306202756_0006_m_000000_4: Committed
18/03/06 20:27:56 INFO Executor: Finished task 0.0 in stage 6.0 (TID 4). 2014 bytes result sent to driver
18/03/06 20:27:57 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
18/03/06 20:27:57 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
tdown
