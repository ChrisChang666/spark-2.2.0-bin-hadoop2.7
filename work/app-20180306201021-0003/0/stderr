Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
18/03/06 20:10:23 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 22022@onehaohdd
18/03/06 20:10:23 INFO SignalUtils: Registered signal handler for TERM
18/03/06 20:10:23 INFO SignalUtils: Registered signal handler for HUP
18/03/06 20:10:23 INFO SignalUtils: Registered signal handler for INT
18/03/06 20:10:25 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
18/03/06 20:10:25 WARN Utils: Your hostname, onehaohdd resolves to a loopback address: 127.0.1.1; using 192.168.0.112 instead (on interface wlan0)
18/03/06 20:10:25 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
18/03/06 20:10:25 INFO SecurityManager: Changing view acls to: onehao
18/03/06 20:10:25 INFO SecurityManager: Changing modify acls to: onehao
18/03/06 20:10:25 INFO SecurityManager: Changing view acls groups to: 
18/03/06 20:10:25 INFO SecurityManager: Changing modify acls groups to: 
18/03/06 20:10:25 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(onehao); groups with view permissions: Set(); users  with modify permissions: Set(onehao); groups with modify permissions: Set()
18/03/06 20:10:26 INFO TransportClientFactory: Successfully created connection to /192.168.0.112:56368 after 204 ms (0 ms spent in bootstraps)
18/03/06 20:10:27 INFO SecurityManager: Changing view acls to: onehao
18/03/06 20:10:27 INFO SecurityManager: Changing modify acls to: onehao
18/03/06 20:10:27 INFO SecurityManager: Changing view acls groups to: 
18/03/06 20:10:27 INFO SecurityManager: Changing modify acls groups to: 
18/03/06 20:10:27 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(onehao); groups with view permissions: Set(); users  with modify permissions: Set(onehao); groups with modify permissions: Set()
18/03/06 20:10:27 INFO TransportClientFactory: Successfully created connection to /192.168.0.112:56368 after 4 ms (0 ms spent in bootstraps)
18/03/06 20:10:27 INFO DiskBlockManager: Created local directory at /tmp/spark-03a3315f-7b10-415b-b73d-05272bc2f85f/executor-da71d715-3b8a-42a4-ae19-22cfc8580bcf/blockmgr-67b5141d-9222-48aa-ac67-9cdee0040534
18/03/06 20:10:27 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
18/03/06 20:10:28 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@192.168.0.112:56368
18/03/06 20:10:28 INFO WorkerWatcher: Connecting to worker spark://Worker@192.168.0.112:60291
18/03/06 20:10:28 INFO TransportClientFactory: Successfully created connection to /192.168.0.112:60291 after 7 ms (0 ms spent in bootstraps)
18/03/06 20:10:28 INFO WorkerWatcher: Successfully connected to spark://Worker@192.168.0.112:60291
18/03/06 20:10:28 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
18/03/06 20:10:28 INFO Executor: Starting executor ID 0 on host 192.168.0.112
18/03/06 20:10:28 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42313.
18/03/06 20:10:28 INFO NettyBlockTransferService: Server created on 192.168.0.112:42313
18/03/06 20:10:28 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
18/03/06 20:10:28 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(0, 192.168.0.112, 42313, None)
18/03/06 20:10:28 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(0, 192.168.0.112, 42313, None)
18/03/06 20:10:28 INFO BlockManager: Initialized BlockManager: BlockManagerId(0, 192.168.0.112, 42313, None)
18/03/06 20:10:28 INFO CoarseGrainedExecutorBackend: Got assigned task 0
18/03/06 20:10:28 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
18/03/06 20:10:28 INFO Executor: Fetching spark://192.168.0.112:56368/jars/data-algorithms-1.0.0.jar with timestamp 1520338220610
18/03/06 20:10:28 INFO TransportClientFactory: Successfully created connection to /192.168.0.112:56368 after 9 ms (0 ms spent in bootstraps)
18/03/06 20:10:28 INFO Utils: Fetching spark://192.168.0.112:56368/jars/data-algorithms-1.0.0.jar to /tmp/spark-03a3315f-7b10-415b-b73d-05272bc2f85f/executor-da71d715-3b8a-42a4-ae19-22cfc8580bcf/spark-9f05ee35-edb7-469e-af5c-438a96778fc9/fetchFileTemp4641927928728977987.tmp
18/03/06 20:10:28 INFO Utils: Copying /tmp/spark-03a3315f-7b10-415b-b73d-05272bc2f85f/executor-da71d715-3b8a-42a4-ae19-22cfc8580bcf/spark-9f05ee35-edb7-469e-af5c-438a96778fc9/-3138065581520338220610_cache to /home/onehao/soft/spark-2.2.0-bin-hadoop2.7/work/app-20180306201021-0003/0/./data-algorithms-1.0.0.jar
18/03/06 20:10:28 INFO Executor: Adding file:/home/onehao/soft/spark-2.2.0-bin-hadoop2.7/work/app-20180306201021-0003/0/./data-algorithms-1.0.0.jar to class loader
18/03/06 20:10:29 INFO TorrentBroadcast: Started reading broadcast variable 1
18/03/06 20:10:29 INFO TransportClientFactory: Successfully created connection to /192.168.0.112:46708 after 3 ms (0 ms spent in bootstraps)
18/03/06 20:10:29 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.1 KB, free 366.3 MB)
18/03/06 20:10:29 INFO TorrentBroadcast: Reading broadcast variable 1 took 463 ms
18/03/06 20:10:29 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 3.6 KB, free 366.3 MB)
18/03/06 20:10:29 INFO HadoopRDD: Input split: hdfs://localhost:9000/user/onehao/workspace/data-algorithms-book/time_series.txt:0+88
18/03/06 20:10:29 INFO TorrentBroadcast: Started reading broadcast variable 0
18/03/06 20:10:29 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 22.9 KB, free 366.3 MB)
18/03/06 20:10:29 INFO TorrentBroadcast: Reading broadcast variable 0 took 33 ms
18/03/06 20:10:30 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 320.9 KB, free 366.0 MB)
18/03/06 20:10:32 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 2335 bytes result sent to driver
18/03/06 20:10:32 INFO CoarseGrainedExecutorBackend: Got assigned task 1
18/03/06 20:10:32 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
18/03/06 20:10:32 INFO TorrentBroadcast: Started reading broadcast variable 2
18/03/06 20:10:32 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.6 KB, free 366.0 MB)
18/03/06 20:10:32 INFO TorrentBroadcast: Reading broadcast variable 2 took 28 ms
18/03/06 20:10:32 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 4.7 KB, free 366.0 MB)
18/03/06 20:10:32 INFO HadoopRDD: Input split: hdfs://localhost:9000/user/onehao/workspace/data-algorithms-book/time_series.txt:0+88
18/03/06 20:10:33 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1939 bytes result sent to driver
18/03/06 20:10:33 INFO CoarseGrainedExecutorBackend: Got assigned task 2
18/03/06 20:10:33 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
18/03/06 20:10:33 INFO MapOutputTrackerWorker: Updating epoch to 1 and clearing cache
18/03/06 20:10:33 INFO TorrentBroadcast: Started reading broadcast variable 3
18/03/06 20:10:33 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 1867.0 B, free 365.9 MB)
18/03/06 20:10:33 INFO TorrentBroadcast: Reading broadcast variable 3 took 29 ms
18/03/06 20:10:33 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 3.3 KB, free 365.9 MB)
18/03/06 20:10:33 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them
18/03/06 20:10:33 INFO MapOutputTrackerWorker: Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@192.168.0.112:56368)
18/03/06 20:10:33 INFO MapOutputTrackerWorker: Got the output locations
18/03/06 20:10:33 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/03/06 20:10:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 13 ms
18/03/06 20:10:33 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 2425 bytes result sent to driver
18/03/06 20:10:33 INFO CoarseGrainedExecutorBackend: Got assigned task 3
18/03/06 20:10:33 INFO Executor: Running task 0.0 in stage 4.0 (TID 3)
18/03/06 20:10:33 INFO TorrentBroadcast: Started reading broadcast variable 4
18/03/06 20:10:33 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 25.8 KB, free 365.9 MB)
18/03/06 20:10:33 INFO TorrentBroadcast: Reading broadcast variable 4 took 43 ms
18/03/06 20:10:33 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 72.2 KB, free 365.9 MB)
18/03/06 20:10:33 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/03/06 20:10:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/03/06 20:10:33 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
18/03/06 20:10:34 INFO FileOutputCommitter: Saved output of task 'attempt_20180306201033_0004_m_000000_3' to hdfs://localhost:9000/user/onehao/output/_temporary/0/task_20180306201033_0004_m_000000
18/03/06 20:10:34 INFO SparkHadoopMapRedUtil: attempt_20180306201033_0004_m_000000_3: Committed
18/03/06 20:10:34 INFO Executor: Finished task 0.0 in stage 4.0 (TID 3). 2014 bytes result sent to driver
18/03/06 20:10:34 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
18/03/06 20:10:34 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
tdown
